{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0141ea34-0b3a-47d9-bc2f-7adead0306aa",
   "metadata": {},
   "source": [
    "### Information Retrieval Pipeline\n",
    "In this notebook, we prototype the IR product that will <b>recieve an input string and return the most relevant offers</b> to the user with respect to that code. These are the steps taken to achieve this:\n",
    "- Load libraries and define functions.\n",
    "- Given an input text, <b>get the category</b> classified by our TypeDetector service which we consume through an API.\n",
    "- Depending on the response (0 = Retail, 1 = Brand, 2 = Category) we perform a specific treatment.\n",
    "- If the <b>type of query is 0 or 1</b>, we search for a match with our unique retailers or brands by performing <b>TF-IDF</b> and <b>Cosine Similarity</b>.\n",
    "- Also, we compute a '<b>fuzzy similarity</b> score' in case there are typeos, which can be helpful if the cosine similarity doesn't bring relevant results.\n",
    "- Next, we fetch offers that come from our matched retailers or brands, only if the cosine similarity is > 0.9 or the fuzzy similarity is > 0.75\n",
    "- If the <b>type of query is 2</b>, then the similarity of the term is compared to offers directly, and synonyms of the terms are computed and also compared to the offers to contemplate a wider range of relevant results.\n",
    "- Finally, the relevant offers are returned in a json list along with a log of activity.\n",
    "\n",
    "<b>*IMPORTANT NOTE</b>: the similarity score is only returned if the type of query is 'category' as in the other cases the only match is with respect to the retailer or brand and that similarity is returned in the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb23524-0466-411d-bf76-de29334e93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7c5bae-fe96-4799-baeb-82ef5a76d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some functions to use in the process\n",
    "\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "def getSynonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name().replace('_', ' '))\n",
    "    # Remove duplicates\n",
    "    synonyms = list(set(synonyms))\n",
    "    return synonyms\n",
    "\n",
    "def listToJson(string_list):\n",
    "    json_list = []\n",
    "    for item in string_list:\n",
    "        json_object = {\n",
    "            'concept': item,\n",
    "            'cosine_similarity': -1,\n",
    "            'fuzzy_score': -1\n",
    "        }\n",
    "        json_list.append(json_object)\n",
    "    return json_list\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "def getTopSortedSimilarityMatches(input_text, target_list):\n",
    "    '''\n",
    "    Returns the top sorted matches of the list with respect to the input text (TF-IDF -> cosine similarity) if similarity > 0,\n",
    "    If no matches are found, it triew using 'fuzzy' matches to compensate for misspelling.\n",
    "    '''\n",
    "    documents = [input_text] + target_list\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 3))\n",
    "\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "\n",
    "    sorted_index = np.argsort(-cosine_similarities)\n",
    "    sorted_retailers = [target_list[i] for i in sorted_index]\n",
    "    sorted_similarities = [cosine_similarities[i] for i in sorted_index]\n",
    "\n",
    "    lst_resp = []\n",
    "\n",
    "    for i, retailer in enumerate(sorted_retailers):\n",
    "        if sorted_similarities[i] > 0:\n",
    "            lst_resp.append({'concept': retailer, 'cosine_similarity': sorted_similarities[i], 'fuzzy_score' : -1})\n",
    "    \n",
    "    # If the list is empty, try using fuzzy matching as a fallback\n",
    "    if not lst_resp:\n",
    "        highest = process.extractOne(input_text, target_list)\n",
    "        if highest:\n",
    "            lst_resp.append({'concept': highest[0], 'cosine_similarity':-1, 'fuzzy_score': highest[1]/100.0})\n",
    "    \n",
    "    return lst_resp\n",
    "\n",
    "def getCategory(text_input):\n",
    "    '''\n",
    "    This function calls our other 'QueryTypeDetector' service and returns the category and confidence.\n",
    "    '''\n",
    "    url = \"http://20.51.242.109:5000/predict\"\n",
    "    data = {\"text\": text_input}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "    #print(\"Status Code:\", response.status_code)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32751f90-4c43-4b46-8bb1-ae96e081608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a sample 'input' to test the pipeline and store in the log.\n",
    "\n",
    "input_text = 'sams club membership'\n",
    "log_list = [f'Input text recieved was \"{input_text}\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b06bc35e-4d31-4099-a748-13c6b0842194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's call our TypeDetector service\n",
    "\n",
    "category_json = getCategory(input_text)\n",
    "deducted_category = category_json['prediction']\n",
    "log_list.append(f'Input categorized by QueryTypeDetection : {category_json[\"prediction\"]} with confidence: {category_json[\"confidence\"]} (0=retail, 1=brand, 2=category)')\n",
    "deducted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ca90664-59b0-4c22-81c4-6a1d828e25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique retailers: 61\n",
      "Number of unique brands: 121\n",
      "Number of unique categories: 141\n",
      "Number of unique offers: 376\n"
     ]
    }
   ],
   "source": [
    "# Let's get unique retailers, brands and categories\n",
    "\n",
    "df_offer_retailer = pd.read_csv('data/offer_retailer.csv')\n",
    "df_cat = pd.read_csv('data/categories.csv')\n",
    "df_brand_category = pd.read_csv('data/brand_category.csv')\n",
    "\n",
    "unique_retailers = list(set([r['RETAILER'] for i, r in df_offer_retailer.iterrows() if not isNaN(r['RETAILER'])]))\n",
    "unique_brands = list(set([r['BRAND'] for i, r in df_offer_retailer.iterrows() if (r['BRAND'] != r['RETAILER']) & (not isNaN(r['BRAND']))]))\n",
    "unique_categories = list(set([r['PRODUCT_CATEGORY'] for i, r in df_cat.iterrows() if not isNaN(r['PRODUCT_CATEGORY'])]))\n",
    "unique_categories += list(set([r['IS_CHILD_CATEGORY_TO'] for i, r in df_cat.iterrows() if not isNaN(r['IS_CHILD_CATEGORY_TO'])]))\n",
    "unique_offers = list(set([r['OFFER'] for i, r in df_offer_retailer.iterrows() if not isNaN(r['OFFER'])]))\n",
    "\n",
    "print(f'Number of unique retailers: {len(unique_retailers)}')\n",
    "print(f'Number of unique brands: {len(unique_brands)}')\n",
    "print(f'Number of unique categories: {len(unique_categories)}')\n",
    "print(f'Number of unique offers: {len(unique_offers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89438f36-f461-41ce-b17c-298c61c0bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Let's extract the 'similarity_list' to use as anchor to fetch the offers, each case requires a special treatment.\n",
    "\n",
    "offer_list = []\n",
    "\n",
    "if deducted_category == 0:\n",
    "    similarity_list = getTopSortedSimilarityMatches(input_text, unique_retailers)\n",
    "    log_list.append(f'Similarity matches with retailers: {similarity_list}')\n",
    "    if len(similarity_list) > 0 and (similarity_list[0]['cosine_similarity'] > 0.9 or similarity_list[0]['fuzzy_score'] > 0.75):\n",
    "        offer_list = getTopSortedSimilarityMatches(input_text, list(df_offer_retailer[df_offer_retailer['RETAILER'] == similarity_list[0]['concept']]['OFFER']))\n",
    "elif deducted_category == 1:\n",
    "    similarity_list = getTopSortedSimilarityMatches(input_text, unique_brands)\n",
    "    log_list.append(f'Similarity matches with brands: {similarity_list}')\n",
    "    if len(similarity_list) > 0 and (similarity_list[0]['cosine_similarity'] > 0.9 or similarity_list[0]['fuzzy_score'] > 0.75):\n",
    "        offer_list = getTopSortedSimilarityMatches(input_text, list(df_offer_retailer[df_offer_retailer['BRAND'] == similarity_list[0]['concept']]['OFFER']))\n",
    "else:\n",
    "    lst_syn = [getTopSortedSimilarityMatches(word, unique_categories) for word in [input_text] + getSynonyms(input_text)]\n",
    "    flat_list = [elem for sublist in lst_syn for elem in sublist]\n",
    "    # Remove duplicates\n",
    "    max_similarity_dict = {}\n",
    "    for item in flat_list:\n",
    "        concept = item['concept']\n",
    "        similarity = item['cosine_similarity']\n",
    "        if concept not in max_similarity_dict or similarity > max_similarity_dict[concept]['cosine_similarity']:\n",
    "            max_similarity_dict[concept] = item\n",
    "    \n",
    "    # Convert the dictionary values to a list to get the final, deduplicated list\n",
    "    similarity_list = list(max_similarity_dict.values())\n",
    "    similarity_list = [item for item in similarity_list if item['cosine_similarity'] > 0 or item['fuzzy_score'] > 0.85]\n",
    "    similarity_list = sorted(similarity_list, key=lambda x: x['cosine_similarity'], reverse=True)\n",
    "    log_list.append(f'Similarity matches with categories: {similarity_list}')\n",
    "\n",
    "    # Get the offer list comparing directly to offers\n",
    "    offer_list = [getTopSortedSimilarityMatches(word, unique_offers) for word in [input_text] + getSynonyms(input_text)]\n",
    "    offer_list = [elem for sublist in offer_list for elem in sublist]\n",
    "    offer_list = sorted(offer_list, key=lambda x: x['cosine_similarity'], reverse=True)\n",
    "    '''\n",
    "    # LINK MATCHED CATEGORIES TO BRANDS AND THEN LINK BRANDS TO OFFERS (TO DO IN LATER STAGES)\n",
    "    unique_target_brands = []\n",
    "    for item in similarity_list:\n",
    "        filtered_df = df_brand_category[df_brand_category['BRAND_BELONGS_TO_CATEGORY'] == item['concept']]\n",
    "        unique_target_brands += list(filtered_df['BRAND'].unique())\n",
    "    unique_target_brands = list(set(unique_target_brands))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "502da0c4-ddac-4519-af3f-35aa91ed9e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'offer_list': [{'concept': 'Spend $50 on a Full-Priced new Club Membership',\n",
       "   'cosine_similarity': 0.17167737713678186,\n",
       "   'fuzzy_score': -1},\n",
       "  {'concept': \"George's Farmers Market Chicken Wings, at Sam's Club\",\n",
       "   'cosine_similarity': 0.07507578805263351,\n",
       "   'fuzzy_score': -1},\n",
       "  {'concept': \"Tyson Products, select varieties, spend $20 at Sam's Club\",\n",
       "   'cosine_similarity': 0.06966444274341704,\n",
       "   'fuzzy_score': -1},\n",
       "  {'concept': 'Spend $110 on a Full-Priced new Plus Membership and receive an ADDITIONAL 10,000 points',\n",
       "   'cosine_similarity': 0.037681749600967825,\n",
       "   'fuzzy_score': -1}],\n",
       " 'LOG_LIST': ['Input text recieved was \"sams club membership\"',\n",
       "  'Input categorized by QueryTypeDetection : 0 with confidence: 0.9963080883026123 (0=retail, 1=brand, 2=category)',\n",
       "  \"Similarity matches with retailers: [{'concept': 'SAMS CLUB', 'cosine_similarity': 0.6725889529793223, 'fuzzy_score': -1}]\",\n",
       "  \"Similarity matches with retailers: [{'concept': 'SAMS CLUB', 'cosine_similarity': 0.6725889529793223, 'fuzzy_score': -1}]\"]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we wrap the response in a json to return as a service.\n",
    "response = {'offer_list':offer_list, 'LOG_LIST':log_list}\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d038c-0541-459a-8612-dc14b602aab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
